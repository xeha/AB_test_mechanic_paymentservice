{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Финальный проект: вариант 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. A/B–тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests \n",
    "from urllib.parse import urlencode\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder as SklearnOneHotEncoder\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(\n",
    "    font_scale=2,\n",
    "    style=\"whitegrid\",\n",
    "    rc={'figure.figsize':(20,7)}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загружаем данные\n",
    "Таблица с группами **groups.csv** \n",
    "\n",
    "### **(!)** Если будет ошибка со стороны Яндекса \"превышен лимит на скачивание файла\", то подгрузим файл локальный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Получаем таблицу с группами\n",
    "# используем api \n",
    "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?' \n",
    "public_key = 'https://disk.yandex.ru/d/hmRKKZTCIr3gnQ' \n",
    "\n",
    "# получаем url \n",
    "final_url = base_url + urlencode(dict(public_key=public_key)) \n",
    "response = requests.get(final_url) \n",
    "download_url_orders = response.json()['href'] \n",
    "\n",
    "#загружаем файл в df \n",
    "download_response = requests.get(download_url_orders) \n",
    "groups_df = pd.read_csv(download_url_orders, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1489</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1627</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1768</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1783</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1794</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id grp\n",
       "0  1489   B\n",
       "1  1627   A\n",
       "2  1768   B\n",
       "3  1783   B\n",
       "4  1794   A"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доп.файл по группам **groups_add.csv** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Получаем доп.таблицу с группами\n",
    "    # используем api \n",
    "    base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?' \n",
    "    public_key = 'https://disk.yandex.ru/d/5Kxrz02m3IBUwQ' \n",
    "\n",
    "    # получаем url \n",
    "    final_url = base_url + urlencode(dict(public_key=public_key)) \n",
    "    response = requests.get(final_url) \n",
    "    download_url_orders = response.json()['href'] \n",
    "\n",
    "    # загружаем файл в df \n",
    "    download_response = requests.get(download_url_orders) \n",
    "    groups_add_df = pd.read_csv(download_url_orders, sep=',')\n",
    "except:\n",
    "    path_groups_add = 'file_groups_add_error.csv'\n",
    "    groups_add_df = pd.read_csv(path_groups_add, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " groups_add_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица с информацией о пользователях, которые зашли на платформу в дни проведения эксперимента **active_studs.csv** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Получаем файл с информацией о пользователях, которые зашли на платформу в дни проведения эксперимента. \n",
    "    # используем api \n",
    "    base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?' \n",
    "    public_key = 'https://disk.yandex.ru/d/Tbs44Bm6H_FwFQ' \n",
    "\n",
    "    # получаем url \n",
    "    final_url = base_url + urlencode(dict(public_key=public_key)) \n",
    "    response = requests.get(final_url) \n",
    "    download_url_orders = response.json()['href'] \n",
    "\n",
    "    # загружаем файл в df \n",
    "    download_response = requests.get(download_url_orders) \n",
    "    active_studs_df = pd.read_csv(download_url_orders, sep=',') \n",
    "except:\n",
    "    path_active_studs = 'active_studs_error'\n",
    "    active_studs_df = pd.read_csv(path_active_studs, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_studs_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица с информацией об оплатах пользователей в дни проведения эксперимента **checks.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Получаем файл с информацией об оплатах пользователей в дни проведения эксперимента.\n",
    "    # используем api \n",
    "    base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?' \n",
    "    public_key = 'https://disk.yandex.ru/d/pH1q-VqcxXjsVA' \n",
    "\n",
    "    # получаем url \n",
    "    final_url = base_url + urlencode(dict(public_key=public_key)) \n",
    "    response = requests.get(final_url) \n",
    "    download_url_orders = response.json()['href'] \n",
    "\n",
    "    # загружаем файл в df \n",
    "    download_response = requests.get(download_url_orders) \n",
    "    checks_df = pd.read_csv(download_url_orders, sep=';') \n",
    "except:\n",
    "    path_checks = 'checks_error'\n",
    "    checks_df = pd.read_csv(path_checks, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Проверим на null и тип данных таблицы группы клиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_add_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_studs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем таблицу с участниками эксперимента на дубликаты\n",
    "active_studs_df.loc[active_studs_df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Собираем общий df  \n",
    "#### 1. Объединим таблицы с группами, и создадим полный справочник клиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_full_df = groups_df.append(groups_add_df)\n",
    "groups_full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1. Проверяем на дубликаты\n",
    "groups_full_df.loc[groups_full_df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2. Оценим соотношение людей в группах\n",
    "count_persosons = sns.countplot(x='grp', data = groups_full_df).set(title='Количество людей в группах')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Добавляем столбец info в таблицу с активными пользователями, чтобы при объединении со справочником всех пользоваталей была возможность отфильтровать активных юзеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_studs_df['info'] = 'были на платформе'\n",
    "active_studs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Объединяем справочник с клиентами и таблицу с активностью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем таблицу всех юзеров с группой тестирования и инфой об активности.\n",
    "all_users = pd.merge(groups_full_df, active_studs_df, how ='left', left_on='id', right_on='student_id').drop('student_id', axis=1)\n",
    "all_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Получаем общий df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1. К таблице с чеками добавляем юзеров, которые были на платформе в день эксперимента.\n",
    "big_df = pd.merge(checks_df, all_users, how ='outer',left_on='student_id', right_on='id').drop('student_id', axis=1)\n",
    "big_df = big_df.query('info==\"были на платформе\" or rev>0').set_index('id')\n",
    "big_df['rev'] = big_df['rev'].fillna(0)\n",
    "# 4.2. Создаем столбец -лейбл, который принимает значение 1, если пользователь совершил покупку и 0 если покупку не совершал.\n",
    "big_df['converted'] = np.where(big_df.rev>0,1,0)\n",
    "big_df = big_df.reset_index()\n",
    "experiment_2_df = big_df\n",
    "big_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Подготовим df для анализа чеков по группам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переведем чеки в целое число и сгруппируем, чтобы посмотреть сколько вариантов оплат существует для пользователей в разных механиках.\n",
    "vs_checks_df = big_df.astype({'rev':'int'})\n",
    "a_checks = vs_checks_df.query('grp==\"A\" & rev>0').rev.value_counts().to_frame().reset_index().rename(columns={'index':'check','rev':'clients_a'}).sort_values('check')\n",
    "b_checks = vs_checks_df.query('grp==\"B\" & rev>0').rev.value_counts().to_frame().reset_index().rename(columns={'index':'check','rev':'clients_b'}).sort_values('check')\n",
    "# Разбиваем чеки группы А на квантили\n",
    "a_checks = a_checks.assign(quan_check_a = pd.qcut(a_checks['check'], q=4,duplicates='drop'))\n",
    "b_checks = b_checks.assign(quan_check_b = pd.qcut(b_checks['check'], q=4,duplicates='drop'))\n",
    "# Объединяем таблицы, чтобы узнать какие чеки наиболее популярны в группах\n",
    "a_b_checks = a_checks.merge(b_checks, how='outer',on='check')\n",
    "# Считаем общее количество клиентов, чтобы высчитать %\n",
    "a_buyers = a_b_checks.clients_a.sum()\n",
    "b_buyers = a_b_checks.clients_b.sum()\n",
    "# считаем % клиентов по группам, по чекам\n",
    "a_b_checks['clients_a_%'] = np.round(((a_b_checks.clients_a/a_buyers)*100),2)\n",
    "a_b_checks['clients_b_%'] = np.round(((a_b_checks.clients_b/b_buyers)*100),2)\n",
    "a_b_checks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Узнаем какой % клиентов какие чеки оставляет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оставляем только нужные столбцы для графика\n",
    "for_bar_pic_df = a_b_checks[['check','clients_a_%','clients_b_%']].set_index('check')\n",
    "plt.figure(figsize=(20,6))\n",
    "# Строим график\n",
    "ab_checks_pic = for_bar_pic_df.plot(kind='bar', stacked=False, color=['#4c72b0', '#dd8452'])\n",
    "plt.title('% клиентов, купивших по чекам')\n",
    "plt.xlabel('check')\n",
    "plt.ylabel('Percentage');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в группе 'B' большая часть чеков (более 30%) приходится на 1900 руб. и ощущется смещение в сторону увеличения чека.  также вариантов оплаты больше. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Узнаем количество вариантов оплаты по группам. (чем отличаются механики)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_variants = vs_checks_df.query('rev>0 ').groupby('grp').agg({'rev':'nunique'}).reset_index()\n",
    "sns.barplot(data= payment_variants, x='grp', y='rev').set(title='Кол-во вариантов оплаты в группах');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. вариантов оплаты больше 20 в обеих группах, поэтому поделим чеки на сегменты для дальнейшего удобства анализа и посчитаем % клиентов по сегментам чеков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Разделяем df на группы для barplot-ов \n",
    "qan_check_a_bar = a_b_checks.groupby('quan_check_a')['clients_a_%'].sum().to_frame().reset_index()\n",
    "qan_check_b_bar = a_b_checks.groupby('quan_check_b')['clients_b_%'].sum().to_frame().reset_index()\n",
    "\n",
    "sns.barplot(data = qan_check_a_bar, x='quan_check_a', y='clients_a_%').set(title='% клиентов в диапазонах чеков (группа А)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = qan_check_b_bar, x='quan_check_b', y='clients_b_%').set(title='% клиентов в диапазонах чеков (группа В)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В группе \"B\" больший % клиентов смещен к высоким чекам, чем в группе \"A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Построим boxplot, увидеть распредление более наглядно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks_box_pic = sns.catplot( data= big_df[big_df['rev']>0], x=\"grp\", y=\"rev\", kind=\"box\").set(title='Распределение чеков, платящих клиентов, по группам')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим **Median Revenue Per Paying User (MRPPU)** - средний платеж на всех платящих пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrppu_by_groups = big_df.query('rev>0').reset_index().groupby(['grp'])\\\n",
    "                .agg(MRPPU = ('rev','median'))\n",
    "mrppu_by_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Сделаем сводный df, чтобы увидеть основные показатели (cr%, ARPU, ARPPU, MRPPU) по группам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3.1. Сгруппируем данные так, чтобы увидеть какова была конверсия для обеих групп.\n",
    "groups = big_df.reset_index().groupby(['grp'])\\\n",
    "                .agg(\\\n",
    "                    ids = ('id','size'),\\\n",
    "                    revenue = ('rev','sum'),\\\n",
    "                    converted =('converted','sum')\\\n",
    "                    )\n",
    "# Добавляем столбец с MRPPU\n",
    "groups = groups.join(mrppu_by_groups)\n",
    "#  Считаем клиентов, которые не делали покупок\n",
    "groups['unconverted'] = groups['ids']-groups['converted']\n",
    "# Считаем % клиентов, которые не делали покупок\n",
    "groups['part_unconv_%'] = np.round(((groups['unconverted']/groups['ids'])*100),2)\n",
    "# Считаем CR% \n",
    "groups['cr_%'] = round(((groups.converted/groups.ids)*100),2)\n",
    "groups['revenue'] = np.round((groups.revenue),2)\n",
    "# # Посчитаем разницу в CR между группами в %\n",
    "groups['diff%_cr_B-A'] = np.round(((groups.loc['B']['cr_%'] - groups.loc['A']['cr_%'])/groups.loc['A']['cr_%']),2)\n",
    "# Посчитаем разницу в ARPU между группами абсолют. и в %\n",
    "groups['ARPU'] = np.round((groups.revenue/groups.ids),2)\n",
    "groups['diff%_ARPU_B-A'] = np.round((((groups.loc['B']['ARPU'] - groups.loc['A']['ARPU']) / groups.loc['A']['ARPU'])*100),2)\n",
    "# Посчитаем разницу в ARPPU между группами абсолют. и в %\n",
    "groups['ARPPU'] = np.round((groups.revenue/groups.converted),2)\n",
    "# groups['diff_ARPPU_B-A'] = np.round((groups.loc['B']['ARPPU'] - groups.loc['A']['ARPPU']),2)\n",
    "groups['diff%_ARPPU_B-A'] = np.round((((groups.loc['B']['ARPPU'] - groups.loc['A']['ARPPU']) / groups.loc['A']['ARPPU'])*100),2)\n",
    "groups['diff%_MRPPU_B-A'] = np.round((((groups.loc['B']['MRPPU'] - groups.loc['A']['MRPPU']) / groups.loc['A']['MRPPU'])*100),2)\n",
    "# Посчитаем % клиентов в группах\n",
    "groups['%_clients'] = np.round(((groups['ids']/(groups.loc['A']['ids'] + groups.loc['B']['ids']))*100),2)\n",
    "groups = groups.reset_index()\n",
    "summary_deviation = groups[['grp','%_clients','cr_%','ARPU','ARPPU','MRPPU']]\n",
    "summary_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Формируем табличку с изменениями по основным метрикам (в %) по группам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_deviation_a_b = groups[[ 'diff%_cr_B-A','diff%_ARPU_B-A','diff%_ARPPU_B-A', 'diff%_MRPPU_B-A']]\n",
    "a_vs_b_deviation = summary_deviation_a_b.stack().to_frame().reset_index().query('level_0==0')\\\n",
    "                    .rename(columns={'level_0':'index', 'level_1':'metric'})\n",
    "a_vs_b_deviation = a_vs_b_deviation.rename(columns= {a_vs_b_deviation.columns[2]:'B_vs_A_%'})\n",
    "a_vs_b_deviation['A'] = 100 + a_vs_b_deviation['B_vs_A_%']\n",
    "a_vs_b_deviation['B'] = 100 - a_vs_b_deviation['B_vs_A_%']\n",
    "a_vs_b_deviation[['metric','B_vs_A_%']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из таблицы изменение в конверсии между группами не значительно, а показатели ARPU (+18%),ARPPU (+28%), и MRPPU (+35%) в пользу тестовой группы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Отразим на графике изменения по основным метрикам (в %) по группам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_stacked_deviation = a_vs_b_deviation[['metric','A','B']].set_index('metric')\n",
    "for_stacked_deviation.plot(kind='bar', stacked=False, color=['#4c72b0', '#dd8452']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось проверить являются ли эти изменения статистически значимыми"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Проверка гипотез \n",
    "###  I Фиксируем гипотезы (CR)\n",
    "**H0** - новая механика оплаты услуг на сайте НЕ влияет на конверсию в покупку <br>\n",
    "**H1** - новая механика оплаты услуг на сайте влияет на конверсию в покупку <br> \n",
    "<br> Уровень значимости p= 0.05 <br>\n",
    "\n",
    "#### 1. Готовим таблицу для хи-теста \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оставляем только нужные столбцы из df\n",
    "experiment_2_df = experiment_2_df[['grp','converted']]\n",
    "# 1) разделяем группы на два отдельных датафрейма\n",
    "a = experiment_2_df[experiment_2_df['grp'] == 'A']\n",
    "b = experiment_2_df[experiment_2_df['grp'] == 'B']\n",
    "# 2) A-purchase, A-nopurchase, B-purchase, B-nopurchase\n",
    "a_purchase = a.converted.sum()\n",
    "a_nopurchase = a.converted.size - a.converted.sum()\n",
    "b_purchase = b.converted.sum()\n",
    "b_nopurchase = b.converted.size - b.converted.sum()\n",
    "# 3) Создаем массив\n",
    "T = np.array([[a_purchase, a_nopurchase], [b_purchase, b_nopurchase]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3. Запускаем тест\n",
    "import scipy\n",
    "from scipy import stats\n",
    "print(scipy.stats.chi2_contingency(T,correction=False)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод по тесту: \n",
    "Значение р было рассчитано на уровне 40%. При 5-процентный уровене значимости, мы можем сделать вывод, что p-значение больше альфы и что мы не отвергаем нулевую гипотезу. Проще говоря, нет никакой разницы в конверсиях между старой и новой механикой оплаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II Фиксируем гипотезы (Median Revenue Per Paying User) <br>\n",
    "**H0** - новая механика оплаты услуг на сайте НЕ влияет на MRPPU <br>\n",
    "**H1** - новая механика оплаты услуг на сайте влияет на MRPPU <br> \n",
    "<br> Уровень значимости p= 0.05 <br>\n",
    "\n",
    "#### Посчитаем p-value тремя способами: t-тест, U-тест, бутстрап средних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value U-test\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "mann_result = mannwhitneyu(big_df.query('rev>0 & grp==\"A\"')['rev'], big_df.query('rev>0 & grp==\"B\"')['rev'])\n",
    "mann_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат:** p_value<0.05 Распределения значимо отличаются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value T-test\n",
    "from scipy import stats\n",
    "\n",
    "t_test_result = stats.ttest_ind(big_df.query('rev>0 & grp==\"A\"')['rev'], big_df.query('rev>0 & grp==\"B\"')['rev'])\n",
    "t_test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат:** p_value < 0.05 , отклоняем нулевую гипотезу. Различия стат. значимы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value bootstrap\n",
    "\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "def get_bootstrap(\n",
    "    data_column_1, # числовые значения первой выборки\n",
    "    data_column_2, # числовые значения второй выборки\n",
    "    boot_it = 1000, # количество бутстрэп-подвыборок\n",
    "    statistic = np.median, # интересующая нас статистика\n",
    "    bootstrap_conf_level = 0.95 # уровень значимости\n",
    "):\n",
    "    boot_data = []\n",
    "    for i in tqdm(range(boot_it)): # извлекаем подвыборки\n",
    "        samples_1 = data_column_1.sample(\n",
    "            len(data_column_1), \n",
    "            replace = True # параметр возвращения\n",
    "        ).values\n",
    "        \n",
    "        samples_2 = data_column_2.sample(\n",
    "            len(data_column_1), \n",
    "            replace = True\n",
    "        ).values\n",
    "        \n",
    "        boot_data.append(statistic(samples_1)-statistic(samples_2)) # mean() - применяем статистику\n",
    "        \n",
    "    pd_boot_data = pd.DataFrame(boot_data)\n",
    "        \n",
    "    left_quant = (1 - bootstrap_conf_level)/2\n",
    "    right_quant = 1 - (1 - bootstrap_conf_level) / 2\n",
    "    quants = pd_boot_data.quantile([left_quant, right_quant])\n",
    "        \n",
    "    p_1 = norm.cdf(\n",
    "        x = 0, \n",
    "        loc = np.mean(boot_data), \n",
    "        scale = np.std(boot_data)\n",
    "    )\n",
    "    p_2 = norm.cdf(\n",
    "        x = 0, \n",
    "        loc = -np.mean(boot_data), \n",
    "        scale = np.std(boot_data)\n",
    "    )\n",
    "    p_value = min(p_1, p_2) * 2\n",
    "        \n",
    "    # Визуализация\n",
    "    _, _, bars = plt.hist(pd_boot_data[0], bins = 50)\n",
    "    for bar in bars:\n",
    "        if bar.get_x() <= quants.iloc[0][0] or bar.get_x() >= quants.iloc[1][0]:\n",
    "            bar.set_facecolor('red')\n",
    "        else: \n",
    "            bar.set_facecolor('grey')\n",
    "            bar.set_edgecolor('black')\n",
    "    \n",
    "    plt.style.use('ggplot')\n",
    "    plt.vlines(quants,ymin=0,ymax=50,linestyle='--')\n",
    "    plt.xlabel('boot_data')\n",
    "    plt.ylabel('frequency')\n",
    "    plt.title(\"Histogram of boot_data\")\n",
    "    plt.show()\n",
    "       \n",
    "    return {\"boot_data\": boot_data, \n",
    "            \"quants\": quants, \n",
    "            \"p_value\": p_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booted_data = get_bootstrap(big_df.query('rev>0 & grp==\"B\"')['rev'], big_df.query('rev>0 & grp==\"A\"')['rev']) # в результате хранится разница двух распределений, ДИ и pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value bootstrap\n",
    "p_value_bootstrap = booted_data[\"p_value\"] # альфа\n",
    "p_value_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booted_data[\"quants\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат:** p_value < 0.05 , отклоняем нулевую гипотезу. Различия в медианах стат. значимы. Доверительный интервал не пересекает 0 это означает, что нулевое различие не согласуется в полученными нами данными. А это прямое свидетельство в пользу того, что различие между медианами ненулевое. Таким образом разница в средних между группами находится в диапазоне (150 - 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Проверим данные на соответствия требованиям применения t-testа:\n",
    "##### 1.1. требование к нормальности данных обеих групп при применении t-теста.\n",
    "\n",
    "Построим графики распределния"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(big_df.query('rev>0 & grp==\"A\"')['rev'])\n",
    "sns.distplot(big_df.query('rev>0 & grp==\"B\"')['rev']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ярко выражена ассиметрия, большая часть наблюдений кучкуется в одном месте и есть несколько выделяющихся значений.Фактически это будет влиять на среднее так же, как и выбросы, поэтому при расчете будем брать медиану."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "\n",
    "pg.normality(big_df.query('rev>0'), dv='rev', group='grp', method='normaltest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. требование гомогенности дисперсий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.homoscedasticity(big_df.query('rev>0'), dv='rev', group='grp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** Требования не выполнены, но т.к. выборки в несколько сотен наблюдений, то отклонения от нормальности не так критичны. (нормальность выборочного распределения по ЦПТ и является критичной для t-теста)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b_mean = big_df.query('rev>0 & grp==\"B\"')['rev'].median()\n",
    "a_mean = big_df.query('rev>0 & grp==\"A\"')['rev'].median()\n",
    "\n",
    "percent = np.round((b_mean-a_mean)/a_mean*100,2)\n",
    "\"Результат между тестом и контролем (в медианах) составил \" + str(percent) + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод: <br> \n",
    "Все тесты (u-test,t-test, bootstrap) показали статистически значимые результаты. Исходя из условия задачи (попытка сравнить средние генеральной совокупности) нам  больше подходит t-test т.к. бутстреп создает среднее не из генеральной совокупности, а из выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ответы на вопросы (задание 1):\n",
    "\n",
    "**На какие метрики Вы смотрите в ходе анализа и почему?** <br/>\n",
    "1) Активные пользователи. Нас интересуют только те кто заходил на платформу и\\или оплачивали во время эксперимента. Остальных юзеров из базы мы не учитываем. <br/>\n",
    "2) CR - конверсия в покупку. Важно понимать конвертит ли новая механика в покупку лучше или хуже. <br/>\n",
    "3) ARPU, ARPPU - помогает оценить лояльность клиентов, измерить ценность внесенных изменений в продукт. <br/>\n",
    "4) MRPPU - в эксперименте учавствует вся клиентская база, данные не кластеризованы, поэтому для описания центральной тенденции лучше использоваать медиану. <br/>\n",
    "**Имеются ли различия в показателях и с чем они могут быть связаны?** <br/>\n",
    "Разница в CR% между группами незначительна,составляет 0,56 и связана с естественной флуктуацией. \n",
    "Различия в ARPU,ARPPU, MRPPU k значительны механики оплаты отличаются между собой количеством тарифов и в новой механике смещение идет в строну увеличение чека. Следовательно, новая механика может сильно повлиять на эти показатели.<br/>\n",
    "**Являются ли эти различия статистически значимыми?** <br/>\n",
    "CR - как показали результаты теста хи-квадрат, различия не являются стат.значимыми <br/>\n",
    "MRPPU - во всех трех тестах различия стат.значимы. Из условия задачи ориентируемся на t-test <br/>\n",
    "**Стоит ли запускать новую механику на всех пользователей?** <br/>\n",
    "Стоит, различия в CR не являются стат.значимыми и даже если мы допустили ошибку первого рода, все равно изменение слишком незначительно (-0.08 п.п.). При этом различия между тестом и контролем в медианных чеках составил 35,5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2. SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandahouse as ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройка подвлючения к clickhouse\n",
    "connection_default = {'host': 'http://clickhouse.beslan.pro:8080',\n",
    "                      'database':'default',\n",
    "                      'user':'student', \n",
    "                      'password':'dpo_python_2020'\n",
    "                     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Очень усердные ученики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''\n",
    "SELECT\n",
    "    uniqExact(st_id) AS hardworking\n",
    "FROM    \n",
    "    (\n",
    "    SELECT\n",
    "        st_id,\n",
    "        date_local,\n",
    "        SUM(correct) AS score\n",
    "    FROM    \n",
    "        (\n",
    "        SELECT \n",
    "            st_id,\n",
    "            correct,\n",
    "            toStartOfMonth((timest)) AS date_local\n",
    "        FROM \n",
    "            default.peas\n",
    "        )\n",
    "    GROUP BY st_id,date_local\n",
    "    )\n",
    "HAVING score>=20 \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_count_good_st = ph.read_clickhouse(query=q,connection=connection_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответ 2.1.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_count_good_st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Оптимизация воронки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_task_2_test = '''\n",
    "SELECT\n",
    "    grp,\n",
    "    arpu,\n",
    "    arpau,\n",
    "    cr,\n",
    "    cr_active,\n",
    "    cr_math\n",
    "FROM\n",
    "    (\n",
    "    SELECT\n",
    "        main_table.grp,\n",
    "        dim_users.all_users,\n",
    "        main_table.users,\n",
    "        main_table.money,\n",
    "        main_table.money_AU,\n",
    "        main_table.active_users,\n",
    "        main_table.active_math_users,\n",
    "        main_table.buyers,\n",
    "        main_table.math_buyer,\n",
    "        main_table.active_paying_user,\n",
    "        divide(buyers,all_users)*100 AS cr,\n",
    "        divide(active_paying_user,active_users)*100 AS cr_active,\n",
    "        divide(math_buyer,active_math_users)*100 AS cr_math,\n",
    "        divide(money,all_users) AS arpu,\n",
    "        divide(money_AU,active_users) AS arpau\n",
    "    FROM\n",
    "        (\n",
    "        SELECT\n",
    "            grp,\n",
    "            uniqExact(st_id) AS users,\n",
    "            SUM(money) AS money,\n",
    "            SUM(active_math_true) AS active_math_users,\n",
    "            SUM(active_user) AS active_users,\n",
    "            SUM(cr) AS buyers,\n",
    "            SUM(math_purchase) AS buyers_math,\n",
    "            SUM(money_active_user) AS money_AU,\n",
    "            SUM(math_buyer) AS math_buyer,\n",
    "            SUM(active_paying_user) AS active_paying_user\n",
    "        FROM\n",
    "            (\n",
    "            SELECT \n",
    "                l.st_id,\n",
    "                r.test_grp AS grp,\n",
    "                l.score_total,\n",
    "                l.active_math_true,\n",
    "                l.active_user,\n",
    "                l.cr,\n",
    "                l.money,\n",
    "                l.math_purchase,\n",
    "                CASE WHEN active_user = 1 THEN money ELSE 0 END AS money_active_user,\n",
    "                CASE WHEN active_math_true = 1 AND math_purchase = 1 THEN 1 ELSE 0 END AS math_buyer,\n",
    "                CASE WHEN active_user = 1 AND money>0 THEN 1 ELSE 0 END AS active_paying_user\n",
    "            FROM\n",
    "                (\n",
    "                    SELECT\n",
    "                        CASE WHEN empty(scoring_table.st_id) THEN sales_table.st_id ELSE scoring_table.st_id END AS st_id,\n",
    "                        scoring_table.score_total AS score_total,\n",
    "                        scoring_table.active_math_true AS active_math_true,\n",
    "                        scoring_table.active_user AS active_user,\n",
    "                        sales_table.cr AS cr,\n",
    "                        sales_table.money AS money,\n",
    "                        sales_table.math_purchase AS math_purchase\n",
    "                    FROM    \n",
    "                        (\n",
    "                        SELECT \n",
    "                        st_id,\n",
    "                        SUM(score) AS score_total,\n",
    "                        MAX(active_math_true) AS active_math_true,\n",
    "                        CASE WHEN score_total>10 THEN 1 ELSE 0 END AS active_user\n",
    "                        FROM\n",
    "                            (\n",
    "                            SELECT\n",
    "                                st_id,\n",
    "                                subject,\n",
    "                                score,\n",
    "                                active_math_true\n",
    "                            FROM\n",
    "                                (\n",
    "                                SELECT \n",
    "                                    st_id,\n",
    "                                    subject,\n",
    "                                    SUM(correct) AS score,\n",
    "                                    CASE WHEN subject ='Math' AND score >=2 THEN 1 ELSE 0 END AS active_math_true\n",
    "                                FROM    \n",
    "                                    (\n",
    "                                    SELECT \n",
    "                                        st_id,\n",
    "                                        correct,\n",
    "                                        subject\n",
    "                                    FROM default.peas\n",
    "                                    )\n",
    "                                GROUP BY st_id,subject\n",
    "                                )\n",
    "                            )\n",
    "                        GROUP BY st_id\n",
    "                        ) AS scoring_table\n",
    "                    FULL OUTER JOIN \n",
    "                        (\n",
    "                        SELECT \n",
    "                            st_id,\n",
    "                            SUM(money) AS money,\n",
    "                            MAX(converted) AS cr,\n",
    "                            MAX(math_purchase) AS math_purchase\n",
    "                        FROM \n",
    "                            (\n",
    "                            SELECT\n",
    "                                st_id,\n",
    "                                subject,\n",
    "                                SUM(money) AS money,\n",
    "                                materialize(1) AS converted,\n",
    "                                CASE WHEN subject ='Math' AND money> 0 THEN 1 ELSE 0 END AS math_purchase\n",
    "                            FROM\n",
    "                                (\n",
    "                                SELECT \n",
    "                                    st_id,\n",
    "                                    toDate(sale_time) AS date_local,\n",
    "                                    money,\n",
    "                                    subject\n",
    "                                FROM default.final_project_check\n",
    "                                )\n",
    "                            GROUP BY st_id, subject\n",
    "                            )\n",
    "                        GROUP BY st_id\n",
    "                        ) AS sales_table \n",
    "                    ON scoring_table.st_id = sales_table.st_id \n",
    "                ) AS l\n",
    "        LEFT JOIN \n",
    "            (\n",
    "            SELECT *\n",
    "            FROM default.studs\n",
    "            ) AS r \n",
    "            ON l.st_id = r.st_id\n",
    "            )\n",
    "            GROUP BY grp\n",
    "        ) AS main_table\n",
    "    LEFT JOIN \n",
    "        (\n",
    "        SELECT\n",
    "            test_grp AS grp,\n",
    "            COUNT(DISTINCT st_id) AS all_users\n",
    "        FROM\n",
    "        default.studs\n",
    "        GROUP BY test_grp\n",
    "        ) AS dim_users\n",
    "    ON main_table.grp =  dim_users.grp\n",
    "    )\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#С помощью join split удаляем пробелы и переносы строки, чтобы уменьшить длину запроса\n",
    "result_task_2_test = ph.read_clickhouse(query=\" \".join(q_task_2_test.split()),connection=connection_default)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответ 2.2.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_task_2_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 3.1. Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groups_add():\n",
    "        try:\n",
    "            # Получаем доп.таблицу с группами\n",
    "            # используем api \n",
    "            base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?' \n",
    "            public_key = 'https://disk.yandex.ru/d/5Kxrz02m3IBUwQ' \n",
    "            # получаем url \n",
    "            final_url = base_url + urlencode(dict(public_key=public_key)) \n",
    "            response = requests.get(final_url) \n",
    "            download_url_orders = response.json()['href'] \n",
    "            # загружаем файл в df \n",
    "            download_response = requests.get(download_url_orders) \n",
    "            groups_add_task3 = pd.read_csv(download_url_orders, sep=',')\n",
    "        except:\n",
    "            path = 'file_groups_add_error.csv'\n",
    "            groups_add_task3 = pd.read_csv(path, sep=',')\n",
    "        groups_full = pd.DataFrame( np.concatenate( (groups_df.values, groups_add_task3.values), axis=0 ) )\n",
    "        groups_full.columns = [ 'id', 'grp']\n",
    "        groups_full.drop_duplicates()\n",
    "        # Создаем таблицу всех юзеров с группой тестирования и инфой об активности.\n",
    "        all_users = pd.merge(groups_full, active_studs_df, how ='left', left_on='id', right_on='student_id').drop('student_id', axis=1)\n",
    "        big_df = pd.merge(checks_df, all_users, how ='outer',left_on='student_id', right_on='id').drop('student_id', axis=1)\n",
    "        big_df = big_df.query('info==\"были на платформе\" or rev>0').set_index('id')\n",
    "        big_df['rev'] = big_df['rev'].fillna(0)\n",
    "        # Создаем столбец -лейбл, который принимает значение 1, если пользователь совершил покупку и 0 если покупку не совершал.\n",
    "        big_df['converted'] = np.where(big_df.rev>0,1,0)\n",
    "        groups = big_df.reset_index().groupby(['grp'])\\\n",
    "                .agg(\\\n",
    "                    ids = ('id','size'),\\\n",
    "                    revenue = ('rev','sum'),\\\n",
    "                    converted =('converted','sum')\\\n",
    "                    )\n",
    "        # Добавляем столбец с MRPPU\n",
    "        groups = pd.concat([groups, mrppu_by_groups], axis=1)\n",
    "        #  Считаем клиентов, которые не делали покупок\n",
    "        groups['unconverted'] = groups['ids']-groups['converted']\n",
    "        # Считаем % клиентов, которые не делали покупок\n",
    "        groups['part_unconv_%'] = np.round(((groups['unconverted']/groups['ids'])*100),2)\n",
    "        # Считаем CR% \n",
    "        groups['cr_%'] = round(((groups.converted/groups.ids)*100),2)\n",
    "        groups['revenue'] = np.round((groups.revenue),2)\n",
    "        # # Посчитаем разницу в CR между группами в %\n",
    "        groups['diff%_cr_B-A'] = np.round(((groups.loc['B']['cr_%'] - groups.loc['A']['cr_%'])/groups.loc['A']['cr_%']),2)\n",
    "        # Посчитаем разницу в ARPU между группами абсолют. и в %\n",
    "        groups['ARPU'] = np.round((groups.revenue/groups.ids),2)\n",
    "        groups['diff%_ARPU_B-A'] = np.round((((groups.loc['B']['ARPU'] - groups.loc['A']['ARPU']) / groups.loc['A']['ARPU'])*100),2)\n",
    "        # Посчитаем разницу в ARPPU между группами абсолют. и в %\n",
    "        groups['ARPPU'] = np.round((groups.revenue/groups.converted),2)\n",
    "        # groups['diff_ARPPU_B-A'] = np.round((groups.loc['B']['ARPPU'] - groups.loc['A']['ARPPU']),2)\n",
    "        groups['diff%_ARPPU_B-A'] = np.round((((groups.loc['B']['ARPPU'] - groups.loc['A']['ARPPU']) / groups.loc['A']['ARPPU'])*100),2)\n",
    "        groups['diff%_MRPPU_B-A'] = np.round((((groups.loc['B']['MRPPU'] - groups.loc['A']['MRPPU']) / groups.loc['A']['MRPPU'])*100),2)\n",
    "        # Посчитаем % клиентов в группах\n",
    "        groups['%_clients'] = np.round(((groups['ids']/(groups.loc['A']['ids'] + groups.loc['B']['ids']))*100),2)\n",
    "        f_one_result = groups.reset_index()[\n",
    "            ['grp','%_clients','cr_%','ARPU','ARPPU','MRPPU','diff%_cr_B-A','diff%_ARPU_B-A','diff%_ARPPU_B-A','diff%_MRPPU_B-A']]\n",
    "        return f_one_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 3.1. Результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_groups_add()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 3.2. Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_one_result = get_groups_add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visuals_total(param):\n",
    "    param = param[[ 'diff%_cr_B-A','diff%_ARPU_B-A','diff%_ARPPU_B-A','diff%_MRPPU_B-A']]\n",
    "    param = param.stack().to_frame().reset_index().query('level_0==0')\\\n",
    "                    .rename(columns={'level_0':'index', 'level_1':'metric'})\n",
    "    param = param.rename(columns= {param.columns[2]:'B_vs_A_%'})\n",
    "    param['A'] = 100 + a_vs_b_deviation['B_vs_A_%']\n",
    "    param['B'] = 100 - a_vs_b_deviation['B_vs_A_%']\n",
    "    param = param[['metric','A','B']].set_index('metric').plot(kind='bar', stacked=False, color=['#4c72b0', '#dd8452']);\n",
    "    return param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 3.2. Результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visuals_total(f_one_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
